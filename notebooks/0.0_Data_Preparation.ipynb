{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85e6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed51c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tinggi dan lebar untuk mengubah ukuran frame video\n",
    "IMAGE_HEIGHT_MOBILENET, IMAGE_WIDTH_MOBILENET = 224, 224\n",
    "IMAGE_HEIGHT_MOVINET, IMAGE_WIDTH_MOVINET = 172, 172\n",
    "# Jumlah frame yang akan diambil dari setiap video\n",
    "SEQUENCE_LENGTH_MOBILENET = 16\n",
    "SEQUENCE_LENGTH_MOVINET = 50\n",
    "# Direktori tempat dataset disimpan\n",
    "DATASET_DIR = \"../data/\"\n",
    "# Daftar class untuk klasifikasi\n",
    "CLASSES_LIST = [\"NonViolence\", \"Violence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af347cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, sequence_length=SEQUENCE_LENGTH_MOBILENET, image_height=IMAGE_HEIGHT_MOBILENET, image_width=IMAGE_WIDTH_MOBILENET):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # 1. Dapatkan total frame\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # 2. Tentukan indeks frame yang akan diambil, sampling merata\n",
    "    if total_frames < sequence_length:\n",
    "        # Kalau video terlalu pendek, ambil semua dan ulangi terakhir sampai seq_len\n",
    "        indices = list(range(total_frames)) + [total_frames - 1] * (sequence_length - total_frames)\n",
    "    else:\n",
    "        step = total_frames / sequence_length\n",
    "        indices = [int(i * step) for i in range(sequence_length)]\n",
    "\n",
    "    frames = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            # kalau gagal baca frame, ulangi frame terakhir\n",
    "            frame = frames[-1] if frames else np.zeros((image_height, image_width, 3), np.uint8)\n",
    "        # 3. Centerâ€crop ke square\n",
    "        h, w = frame.shape[:2]\n",
    "        m = min(h, w)\n",
    "        y0 = (h - m) // 2\n",
    "        x0 = (w - m) // 2\n",
    "        crop = frame[y0:y0+m, x0:x0+m]\n",
    "        # 4. Resize, RGB, normalisasi\n",
    "        crop = cv2.resize(crop, (image_height, image_width), interpolation=cv2.INTER_AREA)\n",
    "        rgb  = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(rgb.astype(np.float32) / 255.0)\n",
    "\n",
    "    cap.release()\n",
    "    return np.stack(frames, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927ae49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(sequence_length=SEQUENCE_LENGTH_MOBILENET, image_height=IMAGE_HEIGHT_MOBILENET, image_width=IMAGE_WIDTH_MOBILENET):\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "\n",
    "    # 1. Iterasi melalui setiap kelas\n",
    "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # 2. Dapatkan daftar file video dalam direktori kelas\n",
    "        class_dir = os.path.join(DATASET_DIR, class_name)\n",
    "        files_list = os.listdir(class_dir)\n",
    "\n",
    "        # 3. Iterasi melalui setiap file video\n",
    "        for file_name in files_list:\n",
    "            # a. Bangun path lengkap ke file video\n",
    "            video_file_path = os.path.join(class_dir, file_name)\n",
    "\n",
    "            # b. Ekstrak frame dari video\n",
    "            frames = extract_frames(video_file_path, sequence_length, image_height, image_width)\n",
    "\n",
    "            # c. Periksa apakah jumlah frame sesuai dengan SEQUENCE_LENGTH\n",
    "            if len(frames) == sequence_length:\n",
    "                # d. Simpan data ke dalam list yang sesuai\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    "\n",
    "    # 4. Konversi list ke array NumPy\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # 5. Kembalikan dataset\n",
    "    return features, labels, video_files_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec744521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: NonViolence\n",
      "Extracting Data of Class: Violence\n"
     ]
    }
   ],
   "source": [
    "# Buat dataset\n",
    "features, labels, video_files_paths = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ae66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi label ke one hot encoded format\n",
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b79878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data menjadi 90% data train dan 10% data test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.1, shuffle = True, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cdc5a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 16, 224, 224, 3) (1800, 2)\n",
      "(200, 16, 224, 224, 3) (200, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c794ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Saving the extracted data\n",
    "os.makedirs(\"../data/ProcessedData/\", exist_ok=True)\n",
    "np.save(\"../data/ProcessedData/X_train.npy\", X_train)\n",
    "np.save(\"../data/ProcessedData/y_train.npy\", y_train)\n",
    "np.save(\"../data/ProcessedData/X_test.npy\", X_test)\n",
    "np.save(\"../data/ProcessedData/y_test.npy\", y_test)\n",
    "print(\"Data has been saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93132c97",
   "metadata": {},
   "source": [
    "# MoViNet Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beccead0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: NonViolence\n",
      "Extracting Data of Class: Violence\n"
     ]
    }
   ],
   "source": [
    "# Buat dataset\n",
    "features, labels, video_files_paths = create_dataset(SEQUENCE_LENGTH_MOVINET, IMAGE_HEIGHT_MOVINET, IMAGE_WIDTH_MOVINET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb097176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi label ke one hot encoded format\n",
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d7a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data menjadi 90% data train dan 10% data test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.1, shuffle = True, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d7ac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 50, 172, 172, 3) (1800, 2)\n",
      "(200, 50, 172, 172, 3) (200, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e2a95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE   = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def make_tf_dataset(X, y, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(X))\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_tf_dataset(X_train, y_train, shuffle=True)\n",
    "val_ds   = make_tf_dataset(X_test, y_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bac965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Saving the extracted data\n",
    "os.makedirs(\"../data/ProcessedDataMoViNet/\", exist_ok=True)\n",
    "np.save(\"../data/ProcessedDataMoViNet/X_train.npy\", X_train)\n",
    "np.save(\"../data/ProcessedDataMoViNet/y_train.npy\", y_train)\n",
    "np.save(\"../data/ProcessedDataMoViNet/X_test.npy\", X_test)\n",
    "np.save(\"../data/ProcessedDataMoViNet/y_test.npy\", y_test)\n",
    "print(\"Data has been saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
